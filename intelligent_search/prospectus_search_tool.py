#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ‹›å‹Ÿè¯´æ˜ä¹¦æ™ºèƒ½æ£€ç´¢å·¥å…· - é‡æ„ç‰ˆæœ¬

å®ç°è®©LLMåƒäººç±»ä¸€æ ·æŸ¥é˜…æ‹›å‹Ÿè¯´æ˜ä¹¦çš„æ£€ç´¢åŠŸèƒ½ï¼Œæ”¯æŒï¼š
1. ç›®å½•æŸ¥è¯¢
2. ç« èŠ‚å®šä½æ£€ç´¢  
3. èŒƒå›´é™åˆ¶æ£€ç´¢
4. æ™ºèƒ½æ–‡æœ¬æ‰©å±•
"""

import sys
import os
from typing import Dict, Any, List, Optional

# è®¾ç½®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

# å¯¼å…¥é…ç½®æ–‡ä»¶
from db_config import get_vector_db_config
from model_config import MODEL_CONFIG

# å¯¼å…¥LLMç›¸å…³åº“
from openai import OpenAI

# å¯¼å…¥é‡æ„åçš„æ¨¡å—
from core.file_manager import FileManager
from core.directory_searcher import DirectorySearcher
from utils.page_utils import PageUtils
from utils.chunk_utils import ChunkUtils
from utils.chunk_selector import ChunkSelector
from searchers import KeywordSearcher, VectorSearcher, HybridSearcher, SearchResult


# é»˜è®¤çš„æ£€ç´¢æ„å›¾åˆ°æ£€ç´¢æ¨¡å¼çš„æ˜ å°„ï¼Œå¯æ ¹æ®éœ€è¦æ‰‹åŠ¨è°ƒæ•´
DEFAULT_INTENT_MODE_MAP = {
    "title": "keyword",
    "content": "hybrid",
}


class ProspectusSearchTool:
    """
    æ‹›å‹Ÿè¯´æ˜ä¹¦æ™ºèƒ½æ£€ç´¢å·¥å…· - é‡æ„ç‰ˆæœ¬
    
    æ”¯æŒLLMå¤šè½®è°ƒç”¨ï¼Œé€æ­¥å®šä½å’Œè·å–æ‹›å‹Ÿè¯´æ˜ä¹¦ä¸­çš„ç‰¹å®šä¿¡æ¯
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æ£€ç´¢å·¥å…·"""
        print("[ProspectusSearchTool] æ‹›å‹Ÿè¯´æ˜ä¹¦æ™ºèƒ½æ£€ç´¢å·¥å…·åˆå§‹åŒ–å¼€å§‹...")
        
        # é…ç½®ä¿¡æ¯
        self.vector_config = get_vector_db_config()
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨aliçš„deepseek-v3ï¼‰
        llm_config = MODEL_CONFIG["ali"]["deepseek-v3"]
        self.llm_client = OpenAI(
            api_key=llm_config["api_key"],
            base_url=llm_config["base_url"]
        )
        self.llm_model = llm_config["model"]
        print(f"[ProspectusSearchTool] LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨æ¨¡å‹: {self.llm_model}")
        
        # åˆå§‹åŒ–å„ä¸ªåŠŸèƒ½æ¨¡å—
        self.file_manager = FileManager()
        self.directory_searcher = DirectorySearcher(self.llm_client, self.llm_model)
        self.chunk_selector = ChunkSelector(self.llm_client, self.llm_model)
        
        # åˆå§‹åŒ–æ£€ç´¢å™¨ï¼ˆæ‡’åŠ è½½ï¼Œåœ¨ä½¿ç”¨æ—¶æ‰åˆ›å»ºï¼‰
        self._keyword_searcher = None
        self._vector_searcher = None
        self._hybrid_searcher = None

        # æ£€ç´¢æ„å›¾åˆ°æ£€ç´¢æ¨¡å¼çš„æ˜ å°„ï¼Œå¯æ ¹æ®ä¸šåŠ¡éœ€è¦åœ¨æ­¤è°ƒæ•´
        self.intent_mode_map = DEFAULT_INTENT_MODE_MAP.copy()

        print("[ProspectusSearchTool] æ‹›å‹Ÿè¯´æ˜ä¹¦æ™ºèƒ½æ£€ç´¢å·¥å…·åˆå§‹åŒ–å®Œæˆ")
    
    def search_prospectus(
        self,
        fund_code: str,                           # åŸºé‡‘ä»£ç ï¼ˆå¿…å¡«ï¼‰
        search_info: str,                         # æ£€ç´¢ä¿¡æ¯ï¼ˆå¯ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰
        is_expansion: bool = False,               # æ˜¯å¦æ‰©å‹Ÿï¼ˆé»˜è®¤Falseï¼‰
        start_page: Optional[int] = None,         # èµ·å§‹é¡µç 
        end_page: Optional[int] = None,           # æˆªæ­¢é¡µç 
        start_chunk_id: Optional[int] = None,     # èµ·å§‹chunk_id
        end_chunk_id: Optional[int] = None,       # æˆªæ­¢chunk_id
        expand_before: int = 0,                   # å‘å‰æ‰©å±•æ–‡æœ¬å—æ•°é‡
        expand_after: int = 0                     # å‘åæ‰©å±•æ–‡æœ¬å—æ•°é‡
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ‹›å‹Ÿè¯´æ˜ä¹¦æ™ºèƒ½æ£€ç´¢

        Args:
            fund_code: åŸºé‡‘ä»£ç ï¼Œå¦‚ "180301.SZ"
            search_info: æ£€ç´¢ä¿¡æ¯ï¼Œå¯ä»¥æ˜¯"ç›®å½•"ã€å…·ä½“å†…å®¹æè¿°ï¼Œæˆ–ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºç›´æ¥æŒ‰èŒƒå›´å–æ–‡
            is_expansion: æ˜¯å¦æŸ¥è¯¢æ‰©å‹Ÿæ‹›å‹Ÿè¯´æ˜ä¹¦ï¼ŒFalseä¸ºé¦–å‘
            start_page: èµ·å§‹é¡µç ï¼Œç”¨äºèŒƒå›´é™åˆ¶
            end_page: æˆªæ­¢é¡µç ï¼Œç”¨äºèŒƒå›´é™åˆ¶
            start_chunk_id: èµ·å§‹chunk_idï¼Œç”¨äºèŒƒå›´é™åˆ¶
            end_chunk_id: æˆªæ­¢chunk_idï¼Œç”¨äºèŒƒå›´é™åˆ¶
            expand_before: å‘å‰æ‰©å±•çš„æ–‡æœ¬å—æ•°é‡
            expand_after: å‘åæ‰©å±•çš„æ–‡æœ¬å—æ•°é‡
            æ£€ç´¢æ¨¡å¼ä¼šæ ¹æ®è¯†åˆ«å‡ºçš„æ£€ç´¢æ„å›¾è‡ªåŠ¨é€‰æ‹©ï¼Œå¯é€šè¿‡ `self.intent_mode_map` è°ƒæ•´æ˜ å°„

        Returns:
            Dict[str, Any]: æ ¹æ®æ£€ç´¢æ„å›¾è¿”å›ä¸åŒç»“æ„ï¼š
                - æ ‡é¢˜æ£€ç´¢ï¼šè¿”å›å•æ¡æ­£æ–‡å†…å®¹åŠå…¶é¡µç ã€chunk èŒƒå›´ã€‚
                - å†…å®¹æ£€ç´¢ï¼šè¿”å›å¤šæ¡æ­£æ–‡ç»“æœåˆ—è¡¨ï¼Œæ¯æ¡åŒ…å«æ–‡æœ¬ä¸ä½ç½®ä¿¡æ¯ã€‚
        """

        print(f"[ProspectusSearchTool] å¼€å§‹æ£€ç´¢: åŸºé‡‘={fund_code}, å†…å®¹={search_info[:50]}...")

        intent_for_error = self._infer_intent_for_error(search_info)

        # å‚æ•°éªŒè¯
        validation_result = self._validate_parameters(
            fund_code, search_info, start_page, end_page,
            start_chunk_id, end_chunk_id
        )
        if not validation_result["valid"]:
            return self._create_error_result(validation_result["error"], intent=intent_for_error)

        try:
            # ç¬¬ä¸€æ­¥ï¼šç¡®å®šç›®æ ‡æ‹›å‹Ÿè¯´æ˜ä¹¦æ–‡ä»¶å
            source_file = self.file_manager.determine_prospectus_file(fund_code, is_expansion)
            if not source_file:
                error_msg = f"æœªæ‰¾åˆ°åŸºé‡‘ {fund_code} çš„{'æ‰©å‹Ÿ' if is_expansion else 'é¦–å‘'}æ‹›å‹Ÿè¯´æ˜ä¹¦"
                return self._create_error_result(error_msg, intent=intent_for_error)

            print(f"[ProspectusSearchTool] ç¡®å®šç›®æ ‡æ–‡ä»¶: {source_file}")

            # ç¬¬äºŒæ­¥ï¼šæ ¹æ®æ£€ç´¢ä¿¡æ¯ç±»å‹è¿›è¡Œå¤„ç†
            if search_info == "ç›®å½•":
                # ç‰¹æ®Šå¤„ç†ï¼šè¿”å›å®Œæ•´ç›®å½•ä¿¡æ¯
                return self.directory_searcher.get_directory_content(fund_code, source_file)

            # ä¸€èˆ¬æ–‡æœ¬æ£€ç´¢
            return self._search_general_content(
                fund_code=fund_code,
                source_file=source_file,
                search_info=search_info,
                start_page=start_page,
                end_page=end_page,
                start_chunk_id=start_chunk_id,
                end_chunk_id=end_chunk_id,
                expand_before=expand_before,
                expand_after=expand_after
            )

        except Exception as e:
            error_msg = f"æ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            print(f"[ProspectusSearchTool] {error_msg}")
            return self._create_error_result(error_msg, intent=intent_for_error)
    
    def _validate_parameters(
        self, 
        fund_code: str, 
        search_info: str,
        start_page: Optional[int] = None,
        end_page: Optional[int] = None,
        start_chunk_id: Optional[int] = None,
        end_chunk_id: Optional[int] = None
    ) -> Dict[str, Any]:
        """å‚æ•°éªŒè¯"""
        
        # åŸºé‡‘ä»£ç éªŒè¯
        if not fund_code or not fund_code.strip():
            return {"valid": False, "error": "åŸºé‡‘ä»£ç ä¸èƒ½ä¸ºç©º"}
        
        # æ£€ç´¢ä¿¡æ¯éªŒè¯
        if search_info is None:
            return {"valid": False, "error": "æ£€ç´¢ä¿¡æ¯ä¸èƒ½ä¸ºç©º"}
        
        # é¡µç èŒƒå›´éªŒè¯
        if start_page is not None and end_page is not None:
            if start_page > end_page:
                return {"valid": False, "error": "èµ·å§‹é¡µç ä¸èƒ½å¤§äºæˆªæ­¢é¡µç "}
        
        # chunk_idèŒƒå›´éªŒè¯
        if start_chunk_id is not None and end_chunk_id is not None:
            if start_chunk_id > end_chunk_id:
                return {"valid": False, "error": "èµ·å§‹chunk_idä¸èƒ½å¤§äºæˆªæ­¢chunk_id"}
        
        return {"valid": True}
    
    def _infer_intent_for_error(self, search_info: Optional[str]) -> str:
        """æ ¹æ®æ£€ç´¢ä¿¡æ¯æ¨æ–­é”™è¯¯å“åº”ç»“æ„"""
        if not search_info or search_info == "ç›®å½•":
            return "content"
        try:
            parsed = self._parse_search_intent(search_info)
            return parsed.get("intent", "content")
        except Exception:
            return "content"

    def _search_general_content(
        self,
        fund_code: str,
        source_file: str,
        search_info: str,
        start_page: Optional[int] = None,
        end_page: Optional[int] = None,
        start_chunk_id: Optional[int] = None,
        end_chunk_id: Optional[int] = None,
        expand_before: int = 0,
        expand_after: int = 0
    ) -> Dict[str, Any]:
        """æ‰§è¡Œä¸€èˆ¬å†…å®¹æ£€ç´¢"""

        print("[ProspectusSearchTool] æ‰§è¡Œä¸€èˆ¬å†…å®¹æ£€ç´¢")

        intent = "content"

        try:
            parsed_intent = self._parse_search_intent(search_info)
            intent = parsed_intent['intent']
            normalized_query = parsed_intent['query']
            print(
                f"[ProspectusSearchTool] æ£€ç´¢æ„å›¾: {intent}, å½’ä¸€åŒ–æŸ¥è¯¢: {normalized_query[:80]}"
            )

            search_mode = self._resolve_search_mode(intent)
            print(f"[ProspectusSearchTool] æ ¹æ®æ„å›¾é€‰æ‹©æ£€ç´¢æ¨¡å¼: {search_mode}")

            # 1. è·å–æ–‡ä»¶æ‰€æœ‰è¯­å—ï¼ˆç”¨äºèŒƒå›´é™åˆ¶å’Œè¯­å—æ‰©å±•ï¼‰
            all_chunks = self._get_all_file_chunks(fund_code, source_file)
            if not all_chunks:
                return self._create_error_result("æœªèƒ½è·å–æ–‡ä»¶è¯­å—æ•°æ®", intent=intent)

            print(f"[ProspectusSearchTool] è·å–æ–‡ä»¶è¯­å— {len(all_chunks)} ä¸ª")

            # 2. æ ¹æ®èŒƒå›´å‚æ•°è®¡ç®—å€™é€‰åŒºé—´
            chunk_range_limits = None
            if any(value is not None for value in [start_page, end_page, start_chunk_id, end_chunk_id]):
                range_chunks = ChunkUtils.apply_range_limitations(
                    all_chunks,
                    start_page,
                    end_page,
                    start_chunk_id,
                    end_chunk_id
                )

                if not range_chunks:
                    return self._create_error_result("æŒ‡å®šèŒƒå›´å†…æ— å†…å®¹", intent=intent)

                chunk_range_limits = ChunkUtils.get_chunk_id_range_from_chunks(range_chunks)
                print(
                    f"[ProspectusSearchTool] æ£€ç´¢èŒƒå›´é™å®š chunk_id: {chunk_range_limits[0]}-{chunk_range_limits[1]}"
                )

            # 3. å¦‚æœæ£€ç´¢ä¿¡æ¯ä¸ºç©ºï¼Œç›´æ¥è¿”å›èŒƒå›´å†…æ–‡æœ¬
            if not normalized_query.strip():
                print("[ProspectusSearchTool] æ£€ç´¢ä¿¡æ¯ä¸ºç©ºï¼Œç›´æ¥æŒ‰èŒƒå›´è·å–æ–‡æœ¬å†…å®¹")
                return self._get_range_content(
                    all_chunks,
                    start_page,
                    end_page,
                    start_chunk_id,
                    end_chunk_id,
                    source_file
                )

            # 4. æ‰§è¡Œæ£€ç´¢è·å–å€™é€‰è¯­å—
            candidate_results = self._execute_search(
                normalized_query,
                fund_code,
                source_file,
                search_mode,
                chunk_range_limits,
                intent
            )

            if not candidate_results:
                return self._create_error_result("æœªæ‰¾åˆ°åŒ¹é…çš„å†…å®¹", intent=intent)

            print(f"[ProspectusSearchTool] è·å¾—å€™é€‰è¯­å— {len(candidate_results)} ä¸ª")
            self._log_candidate_chunks(
                label=f"{search_mode}æ£€ç´¢å€™é€‰ï¼ˆåˆå§‹ï¼‰",
                chunks=candidate_results
            )

            # 5. åº”ç”¨èŒƒå›´é™åˆ¶ï¼ˆå†æ¬¡ä¿è¯ç»“æœåœ¨èŒƒå›´å†…ï¼‰
            if start_page or end_page or start_chunk_id or end_chunk_id:
                candidate_results = self._apply_range_filter(
                    candidate_results, start_page, end_page,
                    start_chunk_id, end_chunk_id
                )
                print(f"[ProspectusSearchTool] èŒƒå›´é™åˆ¶åä¿ç•™ {len(candidate_results)} ä¸ªå€™é€‰è¯­å—")
                self._log_candidate_chunks(
                    label="èŒƒå›´é™åˆ¶åçš„å€™é€‰",
                    chunks=candidate_results
                )

            if not candidate_results:
                return self._create_error_result("åº”ç”¨èŒƒå›´é™åˆ¶åæ— åŒ¹é…ç»“æœ", intent=intent)

            if intent == "title":
                best_chunk = self.chunk_selector.select_best_chunk(
                    search_info=search_info,
                    candidate_results=candidate_results,
                    all_chunks=all_chunks,
                    expand_context=True,
                    intent=intent
                )

                if best_chunk is None:
                    note = getattr(self.chunk_selector, "last_selection_note", None)
                    message = note or "æœªæ£€ç´¢åˆ°ç›®æ ‡æ ‡é¢˜æ‰€åœ¨æ–‡æœ¬å—"
                    print(f"[ProspectusSearchTool] LLMæœªé€‰å‡ºæ ‡é¢˜è¯­å—: {message}")
                    return self._create_error_result(message, intent=intent)

                print(f"[ProspectusSearchTool] LLMé€‰æ‹©æœ€ä½³è¯­å—: chunk_id={best_chunk.chunk_id}")
                expanded_results = self._prepare_expanded_results(
                    [best_chunk],
                    all_chunks,
                    expand_before,
                    expand_after
                )
            else:
                expanded_results = self._prepare_expanded_results(
                    candidate_results,
                    all_chunks,
                    expand_before,
                    expand_after
                )

            if not expanded_results:
                return self._create_error_result("è¯­å—æ‰©å±•åæ— æœ‰æ•ˆå†…å®¹", intent=intent)

            print(f"[ProspectusSearchTool] ä¸€èˆ¬å†…å®¹æ£€ç´¢æˆåŠŸï¼Œè¿”å› {len(expanded_results)} æ¡ç»“æœ")

            if intent == "title":
                return self._create_title_success_result(
                    source_file=source_file,
                    results=expanded_results
                )
            return self._create_content_success_result(
                source_file=source_file,
                results=expanded_results
            )

        except Exception as e:
            error_msg = f"ä¸€èˆ¬å†…å®¹æ£€ç´¢å¤±è´¥: {str(e)}"
            print(f"[ProspectusSearchTool] {error_msg}")
            return self._create_error_result(error_msg, intent=intent)

    def _get_all_file_chunks(self, fund_code: str, source_file: str) -> List[SearchResult]:
        """è·å–æ–‡ä»¶çš„æ‰€æœ‰è¯­å—"""
        try:
            # ä½¿ç”¨å…³é”®è¯æ£€ç´¢å™¨è·å–æ‰€æœ‰è¯­å—
            searcher = self._get_keyword_searcher()
            chunks = searcher.get_file_chunks(fund_code, source_file, sort_by_chunk_id=True)
            return chunks
        except Exception as e:
            print(f"[ProspectusSearchTool] è·å–æ–‡ä»¶è¯­å—å¤±è´¥: {e}")
            return []
    
    def _execute_search(
        self, 
        search_info: str, 
        fund_code: str, 
        source_file: str, 
        search_mode: str,
        chunk_range: Optional[tuple],
        intent: str
    ) -> List[SearchResult]:
        """æ‰§è¡ŒæŒ‡å®šæ¨¡å¼çš„æ£€ç´¢"""
        try:
            if search_mode == "keyword":
                searcher = self._get_keyword_searcher()
                return searcher.search(
                    search_info,
                    fund_code,
                    source_file,
                    top_k=10,
                    chunk_range=chunk_range,
                    intent=intent
                )
            elif search_mode == "vector":
                searcher = self._get_vector_searcher()
                return searcher.search(
                    search_info,
                    fund_code,
                    source_file,
                    top_k=10,
                    chunk_range=chunk_range,
                    intent=intent
                )
            elif search_mode == "hybrid":
                searcher = self._get_hybrid_searcher()
                return searcher.search(
                    search_info,
                    fund_code,
                    source_file,
                    top_k=10,
                    chunk_range=chunk_range,
                    intent=intent
                )
            else:
                print(f"[ProspectusSearchTool] æœªçŸ¥çš„æ£€ç´¢æ¨¡å¼: {search_mode}")
                return []
        except Exception as e:
            print(f"[ProspectusSearchTool] æ‰§è¡Œæ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _apply_range_filter(
        self,
        candidate_results: List[SearchResult],
        start_page: Optional[int] = None,
        end_page: Optional[int] = None,
        start_chunk_id: Optional[int] = None,
        end_chunk_id: Optional[int] = None
    ) -> List[SearchResult]:
        """åº”ç”¨èŒƒå›´è¿‡æ»¤"""
        try:
            return ChunkUtils.apply_range_limitations(
                candidate_results, start_page, end_page, 
                start_chunk_id, end_chunk_id
            )
        except Exception as e:
            print(f"[ProspectusSearchTool] åº”ç”¨èŒƒå›´è¿‡æ»¤å¤±è´¥: {e}")
            return candidate_results
    
    def _prepare_expanded_results(
        self,
        candidate_results: List[SearchResult],
        all_chunks: List[SearchResult],
        expand_before: int,
        expand_after: int
    ) -> List[Dict[str, Any]]:
        """æŒ‰å€™é€‰é€æ¡æ‰©å±•å¹¶ç”Ÿæˆç»“æœåˆ—è¡¨"""
        expanded_results: List[Dict[str, Any]] = []

        for order, candidate in enumerate(candidate_results, start=1):
            try:
                expanded_chunks = ChunkUtils.expand_chunks(
                    [candidate], all_chunks, expand_before, expand_after
                )
            except Exception as exc:
                print(f"[ProspectusSearchTool] æ‰©å±•è¯­å—å¤±è´¥: {exc}")
                expanded_chunks = []

            if not expanded_chunks:
                expanded_chunks = [candidate]

            result_entry = self._build_expanded_entry(
                expanded_chunks=expanded_chunks,
                base_chunk=candidate,
                order=order
            )
            expanded_results.append(result_entry)

        return expanded_results

    def _build_expanded_entry(
        self,
        expanded_chunks: List[SearchResult],
        base_chunk: Optional[SearchResult],
        order: int
    ) -> Dict[str, Any]:
        """æ„é€ å•æ¡æ‰©å±•åçš„æ£€ç´¢ç»“æœ"""
        if not expanded_chunks and base_chunk is not None:
            expanded_chunks = [base_chunk]

        # æŒ‰ chunk_id æ’åºï¼Œç¡®ä¿èŒƒå›´è®¡ç®—å‡†ç¡®
        sorted_chunks = sorted(
            expanded_chunks,
            key=lambda chunk: getattr(chunk, 'chunk_id', 0)
        )

        merged_text = ChunkUtils.merge_chunks_text(sorted_chunks)
        start_page, end_page = PageUtils.get_page_range_from_chunks(sorted_chunks)
        start_chunk_id, end_chunk_id = ChunkUtils.get_chunk_id_range_from_chunks(sorted_chunks)
        chunk_ids = [chunk.chunk_id for chunk in sorted_chunks if hasattr(chunk, 'chunk_id')]

        base_chunk_id = getattr(base_chunk, 'chunk_id', None) if base_chunk else None
        base_page_num = getattr(base_chunk, 'page_num', '') if base_chunk else ''

        page_range = [start_page, end_page] if start_page is not None and end_page is not None else None
        chunk_range = [start_chunk_id, end_chunk_id] if start_chunk_id is not None and end_chunk_id is not None else None

        return {
            'order': order,
            'base_chunk_id': base_chunk_id,
            'base_page_num': base_page_num,
            'text': merged_text,
            'start_page': start_page,
            'end_page': end_page,
            'start_chunk_id': start_chunk_id,
            'end_chunk_id': end_chunk_id,
            'page_range': page_range,
            'chunk_range': chunk_range,
            'chunk_ids': chunk_ids
        }

    def _get_range_content(
        self,
        all_chunks: List[SearchResult],
        start_page: Optional[int] = None,
        end_page: Optional[int] = None,
        start_chunk_id: Optional[int] = None,
        end_chunk_id: Optional[int] = None,
        source_file: str = ""
    ) -> Dict[str, Any]:
        """è·å–æŒ‡å®šèŒƒå›´å†…çš„å†…å®¹ï¼ˆå½“æ£€ç´¢ä¿¡æ¯ä¸ºç©ºæ—¶ï¼‰"""
        try:
            # åº”ç”¨èŒƒå›´é™åˆ¶
            range_chunks = ChunkUtils.apply_range_limitations(
                all_chunks, start_page, end_page, start_chunk_id, end_chunk_id
            )

            if not range_chunks:
                return self._create_error_result("æŒ‡å®šèŒƒå›´å†…æ— å†…å®¹", intent="content")

            self._log_candidate_chunks(
                label="èŒƒå›´æ–‡æœ¬è¯­å—",
                chunks=range_chunks,
                limit=10
            )

            expanded_entry = self._build_expanded_entry(
                expanded_chunks=range_chunks,
                base_chunk=range_chunks[0] if range_chunks else None,
                order=1
            )

            return self._create_content_success_result(
                source_file=source_file,
                results=[expanded_entry]
            )
        except Exception as e:
            return self._create_error_result(f"è·å–èŒƒå›´å†…å®¹å¤±è´¥: {str(e)}", intent="content")
    
    def _parse_search_intent(self, search_info: str) -> Dict[str, str]:
        """è§£ææ£€ç´¢æ„å›¾å’ŒçœŸå®æŸ¥è¯¢å†…å®¹"""

        if search_info is None:
            return {"intent": "content", "query": ""}

        raw = search_info.strip()
        if not raw:
            return {"intent": "content", "query": ""}

        prefix_map = {
            "title": ["ç« èŠ‚æ ‡é¢˜æ£€ç´¢ï¼š", "ç« èŠ‚æ ‡é¢˜æ£€ç´¢:"],
            "content": ["å†…å®¹æ£€ç´¢ï¼š", "å†…å®¹æ£€ç´¢:"]
        }

        for intent_key, prefixes in prefix_map.items():
            for prefix in prefixes:
                if raw.startswith(prefix):
                    return {"intent": intent_key, "query": raw[len(prefix):].strip()}

        return {"intent": "content", "query": raw}

    def _resolve_search_mode(self, intent: str) -> str:
        """æ ¹æ®æ£€ç´¢æ„å›¾é€‰æ‹©æ£€ç´¢æ¨¡å¼"""

        mode = self.intent_mode_map.get(intent)
        if mode is None:
            mode = self.intent_mode_map.get("content", "hybrid")

        if mode not in {"keyword", "vector", "hybrid"}:
            print(
                f"[ProspectusSearchTool] æ„å›¾ {intent} æ˜ å°„åˆ°éæ³•æ¨¡å¼ {mode}ï¼Œæ”¹ç”¨é»˜è®¤ hybrid"
            )
            return "hybrid"

        return mode

    def _get_keyword_searcher(self) -> KeywordSearcher:
        """è·å–å…³é”®è¯æ£€ç´¢å™¨ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._keyword_searcher is None:
            self._keyword_searcher = KeywordSearcher()
        return self._keyword_searcher
    
    def _get_vector_searcher(self) -> VectorSearcher:
        """è·å–å‘é‡æ£€ç´¢å™¨ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._vector_searcher is None:
            self._vector_searcher = VectorSearcher()
        return self._vector_searcher
    
    def _get_hybrid_searcher(self) -> HybridSearcher:
        """è·å–æ··åˆæ£€ç´¢å™¨ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._hybrid_searcher is None:
            self._hybrid_searcher = HybridSearcher()
        return self._hybrid_searcher
    
    def close_connections(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        try:
            if self._keyword_searcher:
                self._keyword_searcher.close_connection()
            if self._vector_searcher:
                self._vector_searcher.close_connection()
            if self._hybrid_searcher:
                self._hybrid_searcher.close_connection()
            print("[ProspectusSearchTool] æ‰€æœ‰è¿æ¥å·²å…³é—­")
        except Exception as e:
            print(f"[ProspectusSearchTool] å…³é—­è¿æ¥æ—¶å‡ºé”™: {e}")
    
    def _create_error_result(self, error_msg: str, intent: str = "content") -> Dict[str, Any]:
        """æ ¹æ®æ„å›¾æ„é€ é”™è¯¯ç»“æœ"""
        if intent == "title":
            return {
                "success": False,
                "source_file": None,
                "content": None,
                "start_page": None,
                "end_page": None,
                "start_chunk_id": None,
                "end_chunk_id": None,
                "error": error_msg
            }
        return {
            "success": False,
            "source_file": None,
            "error": error_msg,
            "retrieved_count": 0,
            "retrieved_summary": None,
            "results": []
        }

    def _create_title_success_result(
        self,
        source_file: str,
        results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """æ„é€ æ ‡é¢˜æ£€ç´¢æˆåŠŸç»“æœ"""
        entry = results[0] if results else {}
        return {
            "success": True,
            "source_file": source_file,
            "content": entry.get("text"),
            "start_page": entry.get("start_page"),
            "end_page": entry.get("end_page"),
            "start_chunk_id": entry.get("start_chunk_id"),
            "end_chunk_id": entry.get("end_chunk_id"),
            "error": None
        }

    def _create_content_success_result(
        self,
        source_file: str,
        results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """æ„é€ å†…å®¹æ£€ç´¢æˆåŠŸç»“æœ"""
        formatted_results: List[Dict[str, Any]] = [
            {
                "text": item.get("text"),
                "start_page": item.get("start_page"),
                "end_page": item.get("end_page"),
                "start_chunk_id": item.get("start_chunk_id"),
                "end_chunk_id": item.get("end_chunk_id")
            }
            for item in results
        ]
        retrieved_count = len(formatted_results)
        summary = (
            f"å…±æ£€ç´¢åˆ° {retrieved_count} ä¸ªæ–‡æœ¬ä¿¡æ¯" if retrieved_count else "æœªæ£€ç´¢åˆ°æ–‡æœ¬ä¿¡æ¯"
        )
        return {
            "success": True,
            "source_file": source_file,
            "error": None,
            "retrieved_count": retrieved_count,
            "retrieved_summary": summary,
            "results": formatted_results
        }

    def _log_candidate_chunks(
        self,
        label: str,
        chunks: List[Any],
        max_preview: int = 400,
        limit: Optional[int] = None
    ) -> None:
        """æ‰“å°å€™é€‰æˆ–èŒƒå›´è¯­å—çš„è°ƒè¯•ä¿¡æ¯"""

        total = len(chunks)
        print(f"[ProspectusSearchTool] {label}: å…± {total} ä¸ªè¯­å—")

        if total == 0:
            return

        display_chunks = chunks if limit is None else chunks[:limit]

        for idx, chunk in enumerate(display_chunks, start=1):
            if hasattr(chunk, 'chunk_id'):
                chunk_id = chunk.chunk_id
                page_num = getattr(chunk, 'page_num', '')
                text = getattr(chunk, 'text', '') or ''
                methods = getattr(chunk, 'from_methods', []) or []
            else:
                source = chunk.get('_source', chunk)
                chunk_id = source.get('chunk_id')
                page_num = source.get('page_num', '')
                text = source.get('text', '') or ''
                methods = source.get('from_methods', []) or []

            preview = text.replace('\n', ' ')[:max_preview]
            method_label = ','.join(methods) if methods else '-'
            print(
                f"  - [{idx}/{total}] chunk_id={chunk_id}, page_num={page_num}, æ¥æº={method_label}, é¢„è§ˆ={preview}"
            )

        if limit is not None and total > limit:
            print(f"[ProspectusSearchTool] {label}: ä»…å±•ç¤ºå‰ {limit} ä¸ªè¯­å—ï¼Œå‰©ä½™ {total - limit} ä¸ªæœªå±•å¼€")


# æµ‹è¯•å‡½æ•°
def test_refactored_tool():
    """æµ‹è¯•é‡æ„åçš„å·¥å…·"""
    print("=== æµ‹è¯•é‡æ„åçš„æ‹›å‹Ÿè¯´æ˜ä¹¦æ™ºèƒ½æ£€ç´¢å·¥å…· ===")
    
    try:
        # åˆå§‹åŒ–å·¥å…·
        tool = ProspectusSearchTool()
        print("âœ… é‡æ„åå·¥å…·åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•ç›®å½•æ£€ç´¢
        print("\nğŸ” æµ‹è¯•ç›®å½•æ£€ç´¢...")
        result = tool.search_prospectus(
            fund_code="180301.SZ",
            search_info="ç›®å½•",
            is_expansion=False
        )
        
        if result["success"]:
            print("âœ… ç›®å½•æ£€ç´¢æˆåŠŸ")
            print(f"ğŸ“ æºæ–‡ä»¶: {result['source_file']}")
            print(f"ğŸ“„ é¡µç èŒƒå›´: {result['start_page']}-{result['end_page']}")
            print(f"ğŸ”¢ chunkèŒƒå›´: {result['start_chunk_id']}-{result['end_chunk_id']}")
            print(f"ğŸ“ å†…å®¹é•¿åº¦: {len(result['content'])} å­—ç¬¦")
        else:
            print(f"âŒ ç›®å½•æ£€ç´¢å¤±è´¥: {result['error']}")
        
        # æµ‹è¯•ä¸€èˆ¬å†…å®¹æ£€ç´¢ï¼ˆé¢„æœŸå¤±è´¥ï¼Œå› ä¸ºå°šæœªå®ç°ï¼‰
        print("\nğŸ” æµ‹è¯•ä¸€èˆ¬å†…å®¹æ£€ç´¢...")
        result = tool.search_prospectus(
            fund_code="180301.SZ",
            search_info="åŸºé‡‘è´¹ç”¨",
            is_expansion=False
        )
        
        if result["success"]:
            print("âœ… ä¸€èˆ¬å†…å®¹æ£€ç´¢æˆåŠŸ")
        else:
            print(f"ğŸ“ ä¸€èˆ¬å†…å®¹æ£€ç´¢é¢„æœŸå¤±è´¥: {result['error']}")
        
        print("\nâœ… é‡æ„åå·¥å…·æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_refactored_tool()
